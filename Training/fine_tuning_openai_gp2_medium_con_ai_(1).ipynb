{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30559,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install trl transformers accelerate git+https://github.com/huggingface/peft.git -Uqqq\n",
        "!pip install einops wandb -Uqqq"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:10:23.598283Z",
          "iopub.execute_input": "2024-03-26T14:10:23.598938Z",
          "iopub.status.idle": "2024-03-26T14:11:20.714249Z",
          "shell.execute_reply.started": "2024-03-26T14:10:23.598905Z",
          "shell.execute_reply": "2024-03-26T14:11:20.712958Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-u3mkEAe9GP",
        "outputId": "a7c6cbf3-c83d-44f4-8bbc-1a0a38fbe738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.9/264.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:11:20.717241Z",
          "iopub.execute_input": "2024-03-26T14:11:20.717585Z",
          "iopub.status.idle": "2024-03-26T14:11:46.803964Z",
          "shell.execute_reply.started": "2024-03-26T14:11:20.717553Z",
          "shell.execute_reply": "2024-03-26T14:11:46.803051Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jLf5Gcfe9GQ",
        "outputId": "3e0225d9-d940-477f-c87e-f0e040b5771b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -i https://pypi.org/simple/ bitsandbytes  #newline"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T07:35:45.017641Z",
          "iopub.execute_input": "2024-03-24T07:35:45.017962Z",
          "iopub.status.idle": "2024-03-24T07:35:45.022199Z",
          "shell.execute_reply.started": "2024-03-24T07:35:45.017923Z",
          "shell.execute_reply": "2024-03-24T07:35:45.021314Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4l44l1Xe9GR",
        "outputId": "e6b51e04-e2f1-4b0e-8d8f-c6ea8927925b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple/\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate #newline"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T10:15:45.444050Z",
          "iopub.execute_input": "2024-03-23T10:15:45.444420Z",
          "iopub.status.idle": "2024-03-23T10:15:56.844159Z",
          "shell.execute_reply.started": "2024-03-23T10:15:45.444388Z",
          "shell.execute_reply": "2024-03-23T10:15:56.843252Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVN6C-SXe9GR",
        "outputId": "97f91dc8-aeaa-4e7d-ba7b-002f3fb67393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.99)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from peft import get_peft_model, PeftConfig, PeftModel, LoraConfig, prepare_model_for_kbit_training\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, GenerationConfig, QuantoConfig\n",
        "from trl import SFTTrainer\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:11:46.805323Z",
          "iopub.execute_input": "2024-03-26T14:11:46.805617Z",
          "iopub.status.idle": "2024-03-26T14:11:59.168692Z",
          "shell.execute_reply.started": "2024-03-26T14:11:46.805589Z",
          "shell.execute_reply": "2024-03-26T14:11:59.167922Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDDdTpyBe9GS",
        "outputId": "549ad71a-dff4-42ba-ad57-42b34b2cd0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py:31: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import setup_chat_format"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:11:59.170802Z",
          "iopub.execute_input": "2024-03-26T14:11:59.171383Z",
          "iopub.status.idle": "2024-03-26T14:11:59.186826Z",
          "shell.execute_reply.started": "2024-03-26T14:11:59.171355Z",
          "shell.execute_reply": "2024-03-26T14:11:59.185756Z"
        },
        "trusted": true,
        "id": "hsMODLgWe9GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model with double quantization\n",
        "#model_name = \"PY007/TinyLlama-1.1B-step-50K-105b\"\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-step-50K-105b\"\n",
        "#model_name = \"EleutherAI/gpt-neo-125m\"\n",
        "#model_name = \"openai-community/gpt2\"\n",
        "#model_name = \"openai-community/gpt2-medium\"\n",
        "#model_name = \"openai-community/gpt2-large\"\n",
        "#model_name = 'facebook/opt-350m'\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",                  #new line\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "#tokenizer.pad_token = tokenizer.eos_token  # modification"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:11:59.188135Z",
          "iopub.execute_input": "2024-03-26T14:11:59.188765Z",
          "iopub.status.idle": "2024-03-26T14:12:06.754565Z",
          "shell.execute_reply.started": "2024-03-26T14:11:59.188731Z",
          "shell.execute_reply": "2024-03-26T14:12:06.753555Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "qYsdXKuge9GS",
        "outputId": "6ecc270a-4471-4c2f-d242-fa5bbd4c6dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9659591a4440>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantization_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3049\u001b[0;31m             hf_quantizer.validate_environment(\n\u001b[0m\u001b[1;32m   3050\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_flax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_flax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3051\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0;34m\"Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;34m\"and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-25T05:27:09.845389Z",
          "iopub.execute_input": "2024-03-25T05:27:09.845659Z",
          "iopub.status.idle": "2024-03-25T05:27:09.849940Z",
          "shell.execute_reply.started": "2024-03-25T05:27:09.845636Z",
          "shell.execute_reply": "2024-03-25T05:27:09.848964Z"
        },
        "trusted": true,
        "id": "BY2XEfSHe9GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.all_special_tokens"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:06.755807Z",
          "iopub.execute_input": "2024-03-26T14:12:06.756119Z",
          "iopub.status.idle": "2024-03-26T14:12:06.762664Z",
          "shell.execute_reply.started": "2024-03-26T14:12:06.756093Z",
          "shell.execute_reply": "2024-03-26T14:12:06.761711Z"
        },
        "trusted": true,
        "id": "Rq5Dg5RXe9GT",
        "outputId": "1bc53403-a89e-433e-f796-a7ee8dbdc8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['<|endoftext|>']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:06.763857Z",
          "iopub.execute_input": "2024-03-26T14:12:06.764763Z",
          "iopub.status.idle": "2024-03-26T14:12:06.785047Z",
          "shell.execute_reply.started": "2024-03-26T14:12:06.764730Z",
          "shell.execute_reply": "2024-03-26T14:12:06.784113Z"
        },
        "trusted": true,
        "id": "5bCEYHFfe9GT",
        "outputId": "5302ef1b-eb9b-475f-b43d-f28165b2f280"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "GPT2TokenizerFast(name_or_path='openai-community/gpt2-medium', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model, tokenizer = setup_chat_format(model, tokenizer, resize_to_multiple_of = 64)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-23T10:28:59.935380Z",
          "iopub.execute_input": "2024-03-23T10:28:59.936569Z",
          "iopub.status.idle": "2024-03-23T10:28:59.950559Z",
          "shell.execute_reply.started": "2024-03-23T10:28:59.936505Z",
          "shell.execute_reply": "2024-03-23T10:28:59.949735Z"
        },
        "trusted": true,
        "id": "IgUTEcn2e9GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.eos_token_id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T11:50:21.860824Z",
          "iopub.execute_input": "2024-03-24T11:50:21.861194Z",
          "iopub.status.idle": "2024-03-24T11:50:21.867383Z",
          "shell.execute_reply.started": "2024-03-24T11:50:21.861164Z",
          "shell.execute_reply": "2024-03-24T11:50:21.866305Z"
        },
        "trusted": true,
        "id": "1RCZNaype9GU",
        "outputId": "b1a08b6c-02fa-479a-c763-0c847539eed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 42,
          "output_type": "execute_result",
          "data": {
            "text/plain": "50256"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T07:47:41.245122Z",
          "iopub.execute_input": "2024-03-24T07:47:41.245840Z",
          "iopub.status.idle": "2024-03-24T07:47:41.249895Z",
          "shell.execute_reply.started": "2024-03-24T07:47:41.245805Z",
          "shell.execute_reply": "2024-03-24T07:47:41.248982Z"
        },
        "trusted": true,
        "id": "7PSFeW3Qe9GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.bos_token = tokenizer.eos_token"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T07:42:35.729320Z",
          "iopub.execute_input": "2024-03-24T07:42:35.730107Z",
          "iopub.status.idle": "2024-03-24T07:42:35.734294Z",
          "shell.execute_reply.started": "2024-03-24T07:42:35.730070Z",
          "shell.execute_reply": "2024-03-24T07:42:35.733281Z"
        },
        "trusted": true,
        "id": "bF3Oiih1e9GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.bos_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T07:47:01.291878Z",
          "iopub.execute_input": "2024-03-24T07:47:01.292805Z",
          "iopub.status.idle": "2024-03-24T07:47:01.297275Z",
          "shell.execute_reply.started": "2024-03-24T07:47:01.292767Z",
          "shell.execute_reply": "2024-03-24T07:47:01.296184Z"
        },
        "trusted": true,
        "id": "dgt7OceSe9GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T07:47:49.860690Z",
          "iopub.execute_input": "2024-03-24T07:47:49.861083Z",
          "iopub.status.idle": "2024-03-24T07:47:49.867613Z",
          "shell.execute_reply.started": "2024-03-24T07:47:49.861052Z",
          "shell.execute_reply": "2024-03-24T07:47:49.866691Z"
        },
        "trusted": true,
        "id": "3ObcJqcVe9GV",
        "outputId": "72a2962e-9e94-400c-ac4a-46a5bb44e52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "GPT2TokenizerFast(name_or_path='facebook/opt-350m', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.eos_token_id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T11:50:31.451716Z",
          "iopub.execute_input": "2024-03-24T11:50:31.452059Z",
          "iopub.status.idle": "2024-03-24T11:50:31.458212Z",
          "shell.execute_reply.started": "2024-03-24T11:50:31.452032Z",
          "shell.execute_reply": "2024-03-24T11:50:31.457209Z"
        },
        "trusted": true,
        "id": "uT6Zf_M7e9GV",
        "outputId": "fcb721a8-1bec-4bd2-9518-c259fe217f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "50256"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T11:39:56.942784Z",
          "iopub.execute_input": "2024-03-24T11:39:56.943149Z",
          "iopub.status.idle": "2024-03-24T11:39:56.949250Z",
          "shell.execute_reply.started": "2024-03-24T11:39:56.943119Z",
          "shell.execute_reply": "2024-03-24T11:39:56.948373Z"
        },
        "trusted": true,
        "id": "4Tk_pLDue9GV",
        "outputId": "b8252d67-a307-4b5a-aa26-29f5a5b2bc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "50256"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.all_special_tokens"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T11:39:51.382462Z",
          "iopub.execute_input": "2024-03-24T11:39:51.383328Z",
          "iopub.status.idle": "2024-03-24T11:39:51.388881Z",
          "shell.execute_reply.started": "2024-03-24T11:39:51.383294Z",
          "shell.execute_reply": "2024-03-24T11:39:51.387964Z"
        },
        "trusted": true,
        "id": "v9qSh3-je9GW",
        "outputId": "d6298b1b-8c12-491f-dd30-1d447d9535a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['<|endoftext|>']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.pad_token_id is None:\n",
        "  tokenizer.pad_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:06.786204Z",
          "iopub.execute_input": "2024-03-26T14:12:06.786508Z",
          "iopub.status.idle": "2024-03-26T14:12:06.794376Z",
          "shell.execute_reply.started": "2024-03-26T14:12:06.786483Z",
          "shell.execute_reply": "2024-03-26T14:12:06.793567Z"
        },
        "trusted": true,
        "id": "sLIu92Xse9GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n",
        "tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:06.795364Z",
          "iopub.execute_input": "2024-03-26T14:12:06.795676Z",
          "iopub.status.idle": "2024-03-26T14:12:06.804183Z",
          "shell.execute_reply.started": "2024-03-26T14:12:06.795652Z",
          "shell.execute_reply": "2024-03-26T14:12:06.803334Z"
        },
        "trusted": true,
        "id": "h-3DjX95e9GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"You are a friendly chatbot who always responds is a polite manner\",\n",
        "    },\n",
        "    {\"role\": \"assistant\", \"content\": \"Hey, do you think it is okay to not exercise daily for humans?\"}\n",
        "]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:06.808489Z",
          "iopub.execute_input": "2024-03-26T14:12:06.808758Z",
          "iopub.status.idle": "2024-03-26T14:12:06.817072Z",
          "shell.execute_reply.started": "2024-03-26T14:12:06.808735Z",
          "shell.execute_reply": "2024-03-26T14:12:06.816213Z"
        },
        "trusted": true,
        "id": "4-duyBJWe9GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.apply_chat_template(messages, tokenize = False, add_generation_prompt = False)\n",
        "text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:06.818122Z",
          "iopub.execute_input": "2024-03-26T14:12:06.818382Z",
          "iopub.status.idle": "2024-03-26T14:12:06.864961Z",
          "shell.execute_reply.started": "2024-03-26T14:12:06.818360Z",
          "shell.execute_reply": "2024-03-26T14:12:06.864059Z"
        },
        "trusted": true,
        "id": "26layTNGe9GW",
        "outputId": "242f7d87-64b7-4b2b-bf93-d4d29da33ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'<|user|>\\nYou are a friendly chatbot who always responds is a polite manner<|endoftext|>\\n<|assistant|>\\nHey, do you think it is okay to not exercise daily for humans?<|endoftext|>\\n'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"You are a friendly chatbot who always responds is a polite manner<|endoftext|>Hey, do you think it is okay to not exercise daily for humans?<|endoftext|>\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T11:52:39.744915Z",
          "iopub.execute_input": "2024-03-24T11:52:39.745349Z",
          "iopub.status.idle": "2024-03-24T11:52:39.750898Z",
          "shell.execute_reply.started": "2024-03-24T11:52:39.745310Z",
          "shell.execute_reply": "2024-03-24T11:52:39.749845Z"
        },
        "trusted": true,
        "id": "XEqFXegYe9GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T03:38:31.629279Z",
          "iopub.execute_input": "2024-03-24T03:38:31.630154Z",
          "iopub.status.idle": "2024-03-24T03:38:31.634352Z",
          "shell.execute_reply.started": "2024-03-24T03:38:31.630120Z",
          "shell.execute_reply": "2024-03-24T03:38:31.633343Z"
        },
        "trusted": true,
        "id": "gBAqC0e5e9GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_text = tokenizer(text)\n",
        "decoded_text = tokenizer.decode(decoded_text['input_ids'], skip_special_tokens = False)\n",
        "decoded_text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:06.866158Z",
          "iopub.execute_input": "2024-03-26T14:12:06.867479Z",
          "iopub.status.idle": "2024-03-26T14:12:06.875188Z",
          "shell.execute_reply.started": "2024-03-26T14:12:06.867443Z",
          "shell.execute_reply": "2024-03-26T14:12:06.874361Z"
        },
        "trusted": true,
        "id": "YJZ64_dme9GW",
        "outputId": "aa426c5d-ee85-4e35-e93e-9e312ed7bb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'<|user|>\\nYou are a friendly chatbot who always responds is a polite manner<|endoftext|>\\n<|assistant|>\\nHey, do you think it is okay to not exercise daily for humans?<|endoftext|>\\n'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:06.876361Z",
          "iopub.execute_input": "2024-03-26T14:12:06.876625Z",
          "iopub.status.idle": "2024-03-26T14:12:06.882701Z",
          "shell.execute_reply.started": "2024-03-26T14:12:06.876601Z",
          "shell.execute_reply": "2024-03-26T14:12:06.881861Z"
        },
        "trusted": true,
        "id": "zfUff4T2e9GW",
        "outputId": "a1d02c49-452e-4560-de44-c8cf9e701c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "1024"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"daily_dialog\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:06.883650Z",
          "iopub.execute_input": "2024-03-26T14:12:06.883931Z",
          "iopub.status.idle": "2024-03-26T14:12:49.898020Z",
          "shell.execute_reply.started": "2024-03-26T14:12:06.883904Z",
          "shell.execute_reply": "2024-03-26T14:12:49.897058Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "aeb0b0958052407b8c8c55d3f5b34f55",
            "d587f2ab0de14399b6964f21f1b88737",
            "53c0ef6c1a854362b4248db1ea2fd0f8",
            "fcc854409b1f4a89943801a688fbd1c3",
            "b0d9c6f9ccc5464583dbea405bc82384",
            "4060a49e82b34a64becb909d5822644a"
          ]
        },
        "id": "jHgydPLBe9GX",
        "outputId": "efdcafd1-8fc1-4ee4-bba1-78cc1aa9f9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/3.61M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aeb0b0958052407b8c8c55d3f5b34f55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/334k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d587f2ab0de14399b6964f21f1b88737"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/331k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53c0ef6c1a854362b4248db1ea2fd0f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/11118 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcc854409b1f4a89943801a688fbd1c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0d9c6f9ccc5464583dbea405bc82384"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4060a49e82b34a64becb909d5822644a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.remove_columns([\"act\", \"emotion\"])\n",
        "dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:49.899308Z",
          "iopub.execute_input": "2024-03-26T14:12:49.899606Z",
          "iopub.status.idle": "2024-03-26T14:12:49.913227Z",
          "shell.execute_reply.started": "2024-03-26T14:12:49.899579Z",
          "shell.execute_reply": "2024-03-26T14:12:49.912361Z"
        },
        "trusted": true,
        "id": "nix6NWwze9GX",
        "outputId": "eb45cb1b-0f52-49cb-961a-8646b9ff1891"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['dialog'],\n        num_rows: 11118\n    })\n    validation: Dataset({\n        features: ['dialog'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['dialog'],\n        num_rows: 1000\n    })\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(Data, tokenize, add_generation_prompt):\n",
        "  processed_data = []\n",
        "\n",
        "  for dialogs in Data:\n",
        "    flag = 0\n",
        "    #wrapped_dialogues = [{\"role\" : \"system\", \"content\" : ''}]\n",
        "    wrapped_dialogues = []\n",
        "\n",
        "    for dialog in dialogs['dialog']:\n",
        "      if flag == 0:\n",
        "        wrapped_dialog = {\"role\" : \"user\", \"content\" : dialog}\n",
        "        wrapped_dialogues.append(wrapped_dialog)\n",
        "        flag = 1\n",
        "      else:\n",
        "        wrapped_dialog = {\"role\" : \"assistant\", \"content\" : dialog}\n",
        "        wrapped_dialogues.append(wrapped_dialog)\n",
        "        flag = 0\n",
        "\n",
        "    wrapped_dialogues = tokenizer.apply_chat_template(wrapped_dialogues, tokenize=False)\n",
        "    processed_data.append(wrapped_dialogues)\n",
        "    output  = pd.DataFrame({\"inputs\": processed_data})\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:49.914550Z",
          "iopub.execute_input": "2024-03-26T14:12:49.915363Z",
          "iopub.status.idle": "2024-03-26T14:12:49.924008Z",
          "shell.execute_reply.started": "2024-03-26T14:12:49.915327Z",
          "shell.execute_reply": "2024-03-26T14:12:49.923161Z"
        },
        "trusted": true,
        "id": "sULcwiWNe9GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:49.925263Z",
          "iopub.execute_input": "2024-03-26T14:12:49.925846Z",
          "iopub.status.idle": "2024-03-26T14:12:49.933764Z",
          "shell.execute_reply.started": "2024-03-26T14:12:49.925813Z",
          "shell.execute_reply": "2024-03-26T14:12:49.932916Z"
        },
        "trusted": true,
        "id": "LqSxP1pTe9GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = preprocess_function(dataset['train'], tokenize=False, add_generation_prompt=False)\n",
        "train_ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:49.935055Z",
          "iopub.execute_input": "2024-03-26T14:12:49.935580Z",
          "iopub.status.idle": "2024-03-26T14:12:57.717900Z",
          "shell.execute_reply.started": "2024-03-26T14:12:49.935547Z",
          "shell.execute_reply": "2024-03-26T14:12:57.716999Z"
        },
        "trusted": true,
        "id": "whQel-nne9GX",
        "outputId": "9795735d-6339-477a-8198-e523ac94dbd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                  inputs\n0      <|user|>\\nSay , Jim , how about going for a fe...\n1      <|user|>\\nCan you do push-ups ? <|endoftext|>\\...\n2      <|user|>\\nCan you study with the radio on ? <|...\n3      <|user|>\\nAre you all right ? <|endoftext|>\\n<...\n4      <|user|>\\nHey John , nice skates . Are they ne...\n...                                                  ...\n11113  <|user|>\\nHello , I bought a pen in your shop ...\n11114  <|user|>\\nDo you have any seats available ? <|...\n11115  <|user|>\\nUncle Ben , how did the Forbidden Ci...\n11116  <|user|>\\nMay I help you , sir ? <|endoftext|>...\n11117  <|user|>\\nCould I have the check , please ? <|...\n\n[11118 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inputs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;|user|&gt;\\nSay , Jim , how about going for a fe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;|user|&gt;\\nCan you do push-ups ? &lt;|endoftext|&gt;\\...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;|user|&gt;\\nCan you study with the radio on ? &lt;|...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;|user|&gt;\\nAre you all right ? &lt;|endoftext|&gt;\\n&lt;...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;|user|&gt;\\nHey John , nice skates . Are they ne...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11113</th>\n      <td>&lt;|user|&gt;\\nHello , I bought a pen in your shop ...</td>\n    </tr>\n    <tr>\n      <th>11114</th>\n      <td>&lt;|user|&gt;\\nDo you have any seats available ? &lt;|...</td>\n    </tr>\n    <tr>\n      <th>11115</th>\n      <td>&lt;|user|&gt;\\nUncle Ben , how did the Forbidden Ci...</td>\n    </tr>\n    <tr>\n      <th>11116</th>\n      <td>&lt;|user|&gt;\\nMay I help you , sir ? &lt;|endoftext|&gt;...</td>\n    </tr>\n    <tr>\n      <th>11117</th>\n      <td>&lt;|user|&gt;\\nCould I have the check , please ? &lt;|...</td>\n    </tr>\n  </tbody>\n</table>\n<p>11118 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "O6V_f8vbe9GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:57.719088Z",
          "iopub.execute_input": "2024-03-26T14:12:57.719370Z",
          "iopub.status.idle": "2024-03-26T14:12:57.725101Z",
          "shell.execute_reply.started": "2024-03-26T14:12:57.719346Z",
          "shell.execute_reply": "2024-03-26T14:12:57.724213Z"
        },
        "trusted": true,
        "id": "bzpa_CHHe9GX",
        "outputId": "b2c1b4ae-ace7-4973-a1bb-2b080055e56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "1024"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.model_max_length > 100_000:\n",
        "  tokenizer.model_max_length = 1024"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:57.726244Z",
          "iopub.execute_input": "2024-03-26T14:12:57.726506Z",
          "iopub.status.idle": "2024-03-26T14:12:57.740400Z",
          "shell.execute_reply.started": "2024-03-26T14:12:57.726484Z",
          "shell.execute_reply": "2024-03-26T14:12:57.739437Z"
        },
        "trusted": true,
        "id": "s33xJKaCe9GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = preprocess_function(dataset['validation'], tokenize=False, add_generation_prompt=False)\n",
        "val_ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:57.741591Z",
          "iopub.execute_input": "2024-03-26T14:12:57.741928Z",
          "iopub.status.idle": "2024-03-26T14:12:58.133963Z",
          "shell.execute_reply.started": "2024-03-26T14:12:57.741894Z",
          "shell.execute_reply": "2024-03-26T14:12:58.132906Z"
        },
        "trusted": true,
        "id": "PKmQ2ajFe9GX",
        "outputId": "17e7857a-427a-41fd-ab34-16ab9030e77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                inputs\n0    <|user|>\\nGood morning , sir . Is there a bank...\n1    <|user|>\\nGood afternoon . This is Michelle Li...\n2    <|user|>\\nWhat qualifications should a reporte...\n3    <|user|>\\nHi , good morning , Miss ? what can ...\n4    <|user|>\\nExcuse me , ma'am . Can you tell me ...\n..                                                 ...\n995  <|user|>\\nHello , who is speaking ? <|endoftex...\n996  <|user|>\\nAhh ... What a fine day ! I do feel ...\n997  <|user|>\\nI'm so sorry about your brother , Mr...\n998  <|user|>\\nHi , Jeny.Are still working ? <|endo...\n999  <|user|>\\nWelcome , sir . What can I do for yo...\n\n[1000 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inputs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;|user|&gt;\\nGood morning , sir . Is there a bank...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;|user|&gt;\\nGood afternoon . This is Michelle Li...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;|user|&gt;\\nWhat qualifications should a reporte...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;|user|&gt;\\nHi , good morning , Miss ? what can ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;|user|&gt;\\nExcuse me , ma'am . Can you tell me ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>&lt;|user|&gt;\\nHello , who is speaking ? &lt;|endoftex...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>&lt;|user|&gt;\\nAhh ... What a fine day ! I do feel ...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>&lt;|user|&gt;\\nI'm so sorry about your brother , Mr...</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>&lt;|user|&gt;\\nHi , Jeny.Are still working ? &lt;|endo...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>&lt;|user|&gt;\\nWelcome , sir . What can I do for yo...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [train_ds, val_ds]\n",
        "train_ds = pd.concat(frames)\n",
        "train_ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:58.135193Z",
          "iopub.execute_input": "2024-03-26T14:12:58.135460Z",
          "iopub.status.idle": "2024-03-26T14:12:58.146626Z",
          "shell.execute_reply.started": "2024-03-26T14:12:58.135437Z",
          "shell.execute_reply": "2024-03-26T14:12:58.145652Z"
        },
        "trusted": true,
        "id": "n_Ud010ie9GY",
        "outputId": "289edcc3-cd3e-4af1-ea14-a64d35f610fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 22,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                inputs\n0    <|user|>\\nSay , Jim , how about going for a fe...\n1    <|user|>\\nCan you do push-ups ? <|endoftext|>\\...\n2    <|user|>\\nCan you study with the radio on ? <|...\n3    <|user|>\\nAre you all right ? <|endoftext|>\\n<...\n4    <|user|>\\nHey John , nice skates . Are they ne...\n..                                                 ...\n995  <|user|>\\nHello , who is speaking ? <|endoftex...\n996  <|user|>\\nAhh ... What a fine day ! I do feel ...\n997  <|user|>\\nI'm so sorry about your brother , Mr...\n998  <|user|>\\nHi , Jeny.Are still working ? <|endo...\n999  <|user|>\\nWelcome , sir . What can I do for yo...\n\n[12118 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inputs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;|user|&gt;\\nSay , Jim , how about going for a fe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;|user|&gt;\\nCan you do push-ups ? &lt;|endoftext|&gt;\\...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;|user|&gt;\\nCan you study with the radio on ? &lt;|...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;|user|&gt;\\nAre you all right ? &lt;|endoftext|&gt;\\n&lt;...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;|user|&gt;\\nHey John , nice skates . Are they ne...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>&lt;|user|&gt;\\nHello , who is speaking ? &lt;|endoftex...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>&lt;|user|&gt;\\nAhh ... What a fine day ! I do feel ...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>&lt;|user|&gt;\\nI'm so sorry about your brother , Mr...</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>&lt;|user|&gt;\\nHi , Jeny.Are still working ? &lt;|endo...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>&lt;|user|&gt;\\nWelcome , sir . What can I do for yo...</td>\n    </tr>\n  </tbody>\n</table>\n<p>12118 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = preprocess_function(dataset['test'], tokenize=False, add_generation_prompt=False)\n",
        "test_ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:58.147981Z",
          "iopub.execute_input": "2024-03-26T14:12:58.148319Z",
          "iopub.status.idle": "2024-03-26T14:12:58.539197Z",
          "shell.execute_reply.started": "2024-03-26T14:12:58.148291Z",
          "shell.execute_reply": "2024-03-26T14:12:58.538275Z"
        },
        "trusted": true,
        "id": "sz68lmtbe9GY",
        "outputId": "af036bd5-f715-480a-abf2-76d83e90f382"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                inputs\n0    <|user|>\\nHey man , you wanna buy some weed ? ...\n1    <|user|>\\nThe taxi drivers are on strike again...\n2    <|user|>\\nWe've managed to reduce our energy c...\n3    <|user|>\\nBelieve it or not , tea is the most ...\n4    <|user|>\\nWhat are your personal weaknesses ? ...\n..                                                 ...\n995  <|user|>\\nFrank ’ s getting married , do you b...\n996  <|user|>\\nOK . Come back into the classroom , ...\n997  <|user|>\\nDo you have any hobbies ? <|endoftex...\n998  <|user|>\\nJenny , what's wrong with you ? Why ...\n999  <|user|>\\nWhat a nice day ! <|endoftext|>\\n<|a...\n\n[1000 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inputs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;|user|&gt;\\nHey man , you wanna buy some weed ? ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;|user|&gt;\\nThe taxi drivers are on strike again...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;|user|&gt;\\nWe've managed to reduce our energy c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;|user|&gt;\\nBelieve it or not , tea is the most ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;|user|&gt;\\nWhat are your personal weaknesses ? ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>&lt;|user|&gt;\\nFrank ’ s getting married , do you b...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>&lt;|user|&gt;\\nOK . Come back into the classroom , ...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>&lt;|user|&gt;\\nDo you have any hobbies ? &lt;|endoftex...</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>&lt;|user|&gt;\\nJenny , what's wrong with you ? Why ...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>&lt;|user|&gt;\\nWhat a nice day ! &lt;|endoftext|&gt;\\n&lt;|a...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datasets\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "\n",
        "tdf = train_ds\n",
        "#vdf = df_val\n",
        "testdf = test_ds\n",
        "tds = Dataset.from_pandas(tdf)\n",
        "#vds = Dataset.from_pandas(vdf)\n",
        "testdf = Dataset.from_pandas(testdf)\n",
        "\n",
        "\n",
        "ds = DatasetDict()\n",
        "\n",
        "ds['train'] = tds\n",
        "#ds['validation'] = vds\n",
        "ds['test'] = testdf\n",
        "print(ds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:58.540558Z",
          "iopub.execute_input": "2024-03-26T14:12:58.541137Z",
          "iopub.status.idle": "2024-03-26T14:12:58.636055Z",
          "shell.execute_reply.started": "2024-03-26T14:12:58.541101Z",
          "shell.execute_reply": "2024-03-26T14:12:58.635123Z"
        },
        "trusted": true,
        "id": "p8BCok4We9Gb",
        "outputId": "c8abcd72-312c-4b29-94d5-27229a25ebc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "DatasetDict({\n    train: Dataset({\n        features: ['inputs', '__index_level_0__'],\n        num_rows: 12118\n    })\n    test: Dataset({\n        features: ['inputs'],\n        num_rows: 1000\n    })\n})\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ds['train']\n",
        "eval_dataset = ds['test']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:58.637304Z",
          "iopub.execute_input": "2024-03-26T14:12:58.638138Z",
          "iopub.status.idle": "2024-03-26T14:12:58.645680Z",
          "shell.execute_reply.started": "2024-03-26T14:12:58.638108Z",
          "shell.execute_reply": "2024-03-26T14:12:58.644773Z"
        },
        "trusted": true,
        "id": "XcsZ23Bxe9Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = setup_chat_format(model, tokenizer, resize_to_multiple_of = 64)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:58.646826Z",
          "iopub.execute_input": "2024-03-26T14:12:58.647125Z",
          "iopub.status.idle": "2024-03-26T14:12:59.494079Z",
          "shell.execute_reply.started": "2024-03-26T14:12:58.647100Z",
          "shell.execute_reply": "2024-03-26T14:12:59.493258Z"
        },
        "trusted": true,
        "id": "KHtZfTWfe9Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.all_special_tokens"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:59.495203Z",
          "iopub.execute_input": "2024-03-26T14:12:59.495493Z",
          "iopub.status.idle": "2024-03-26T14:12:59.502206Z",
          "shell.execute_reply.started": "2024-03-26T14:12:59.495467Z",
          "shell.execute_reply": "2024-03-26T14:12:59.501012Z"
        },
        "trusted": true,
        "id": "QDDFokXRe9Gc",
        "outputId": "d6b13016-84a9-4dc7-e976-d26522ad1b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['<|im_start|>', '<|im_end|>', '<|endoftext|>']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "special_tokens_dict = {'additional_special_tokens': ['<|user|>', \"<|assistant|>\"]}\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "print('We have added', num_added_toks, 'tokens')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:59.507375Z",
          "iopub.execute_input": "2024-03-26T14:12:59.507644Z",
          "iopub.status.idle": "2024-03-26T14:12:59.513920Z",
          "shell.execute_reply.started": "2024-03-26T14:12:59.507621Z",
          "shell.execute_reply": "2024-03-26T14:12:59.512940Z"
        },
        "trusted": true,
        "id": "mczuKhXxe9Gc",
        "outputId": "a5caa8be-e394-42fc-a2c6-e908d476b448"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "We have added 2 tokens\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.all_special_tokens"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:12:59.514943Z",
          "iopub.execute_input": "2024-03-26T14:12:59.516115Z",
          "iopub.status.idle": "2024-03-26T14:12:59.525146Z",
          "shell.execute_reply.started": "2024-03-26T14:12:59.516089Z",
          "shell.execute_reply": "2024-03-26T14:12:59.524345Z"
        },
        "trusted": true,
        "id": "ZPTaY8AKe9Gc",
        "outputId": "ed5f0156-920f-4b9d-ffd0-868744020935"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['<|im_start|>', '<|im_end|>', '<|endoftext|>', '<|user|>', '<|assistant|>']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting arguments for low-rank adaptation\n",
        "\n",
        "#model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "lora_alpha = 32 # The weight matrix is scaled by lora_alpha/lora_rank, so I set lora_alpha = lora_rank to remove scaling\n",
        "lora_dropout = 0.05\n",
        "lora_rank = 32\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_rank,\n",
        "    bias=\"none\",  # setting to 'none' for only training weight params instead of biases\n",
        "    task_type=\"CAUSAL_LM\")\n",
        "\n",
        "peft_model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:13:04.942828Z",
          "iopub.execute_input": "2024-03-26T14:13:04.943217Z",
          "iopub.status.idle": "2024-03-26T14:13:05.012924Z",
          "shell.execute_reply.started": "2024-03-26T14:13:04.943190Z",
          "shell.execute_reply": "2024-03-26T14:13:05.011912Z"
        },
        "trusted": true,
        "id": "vGZEtz66e9Gc",
        "outputId": "36b6f3fb-fe93-4375-a06f-c7e9b135bac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting training arguments\n",
        "output_dir = \"SSahas/openai_community_med_e6\"\n",
        "per_device_train_batch_size = 1\n",
        "gradient_accumulation_steps = 1\n",
        "#optim = \"paged_adamw_32bit\"\n",
        "optim = \"adamw_hf\"\n",
        "num_train_epochs = 4\n",
        "save_strategy=\"epoch\"\n",
        "evaluation_strategy = 'steps'\n",
        "#save_steps=\"epoch\"\n",
        "#save_steps = 350\n",
        "logging_steps = 200\n",
        "learning_rate = 9e-4\n",
        "#max_grad_norm = 0.3 # Sets limit for gradient clipping\n",
        "max_steps = 700     # Number of training steps\n",
        "#warmup_ratio = 0.03 # Portion of steps used for learning_rate to warmup from 0\n",
        "lr_scheduler_type = \"cosine\" # I chose cosine to avoid learning plateaus\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    save_strategy = save_strategy,\n",
        "    #evaluation_strategy = evaluation_strategy,\n",
        "    #save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    #max_grad_norm=max_grad_norm,\n",
        "    #max_steps=max_steps,\n",
        "    #warmup_ratio=warmup_ratio,\n",
        "    #lr_scheduler_type=lr_scheduler_type,\n",
        "    push_to_hub=False,\n",
        "    report_to='none'\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:13:19.320496Z",
          "iopub.execute_input": "2024-03-26T14:13:19.320835Z",
          "iopub.status.idle": "2024-03-26T14:13:19.376948Z",
          "shell.execute_reply.started": "2024-03-26T14:13:19.320810Z",
          "shell.execute_reply": "2024-03-26T14:13:19.375925Z"
        },
        "trusted": true,
        "id": "rpeJijgje9Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = tokenizer.model_max_length\n",
        "trainer = SFTTrainer(\n",
        "    model=peft_model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset = eval_dataset,\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_text_field='inputs',\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    #neftune_noise_alpha=5\n",
        ")\n",
        "peft_model.config.use_cache = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:13:19.585760Z",
          "iopub.execute_input": "2024-03-26T14:13:19.586156Z",
          "iopub.status.idle": "2024-03-26T14:13:23.578056Z",
          "shell.execute_reply.started": "2024-03-26T14:13:19.586127Z",
          "shell.execute_reply": "2024-03-26T14:13:23.577101Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "11317b9195264e75842283cfe166dd42",
            "97ab36b1f5aa4b67ac5f13562eb6a012"
          ]
        },
        "id": "enSUArpse9Gc",
        "outputId": "75a4b6c2-9cb1-404f-c776-f2ee5340fa3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/12118 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11317b9195264e75842283cfe166dd42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97ab36b1f5aa4b67ac5f13562eb6a012"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T14:13:26.216584Z",
          "iopub.execute_input": "2024-03-26T14:13:26.216979Z",
          "iopub.status.idle": "2024-03-26T15:24:38.179147Z",
          "shell.execute_reply.started": "2024-03-26T14:13:26.216950Z",
          "shell.execute_reply": "2024-03-26T15:24:38.178223Z"
        },
        "trusted": true,
        "id": "Uug6u2iQe9Gc",
        "outputId": "a3593434-e0c2-4ce5-cca9-a0578fde0275"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='48472' max='48472' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [48472/48472 1:11:10, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>6.610600</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.157500</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.168500</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>2.111200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.118600</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>2.061500</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>2.095200</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>2.072700</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>2.063100</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.062500</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>2.083900</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>2.064000</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>2.024300</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>2.075400</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.971100</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>2.050200</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>2.050500</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>1.995100</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>2.077400</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>2.053400</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>2.015200</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>2.033500</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>2.033600</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>2.054900</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.994200</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>2.072700</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>2.030900</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>2.064300</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>2.029200</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>2.006200</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>2.018600</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>2.026200</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>1.993600</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>2.028800</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>2.006000</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>2.045000</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>1.969800</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>2.009100</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>2.028900</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>2.018900</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>2.003200</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>1.980100</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>2.002200</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>2.011500</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>2.022900</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>1.965800</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>2.034800</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>2.019700</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>1.949600</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>1.980200</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>2.001400</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>1.951700</td>\n    </tr>\n    <tr>\n      <td>10600</td>\n      <td>2.001800</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>1.973400</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>1.983900</td>\n    </tr>\n    <tr>\n      <td>11200</td>\n      <td>2.024300</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>2.000100</td>\n    </tr>\n    <tr>\n      <td>11600</td>\n      <td>1.956100</td>\n    </tr>\n    <tr>\n      <td>11800</td>\n      <td>2.042200</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>1.975600</td>\n    </tr>\n    <tr>\n      <td>12200</td>\n      <td>1.937500</td>\n    </tr>\n    <tr>\n      <td>12400</td>\n      <td>1.920600</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>1.908400</td>\n    </tr>\n    <tr>\n      <td>12800</td>\n      <td>1.873100</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>1.896200</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>1.904000</td>\n    </tr>\n    <tr>\n      <td>13400</td>\n      <td>1.932800</td>\n    </tr>\n    <tr>\n      <td>13600</td>\n      <td>1.950400</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>1.940000</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>1.944100</td>\n    </tr>\n    <tr>\n      <td>14200</td>\n      <td>1.968300</td>\n    </tr>\n    <tr>\n      <td>14400</td>\n      <td>1.912600</td>\n    </tr>\n    <tr>\n      <td>14600</td>\n      <td>1.912500</td>\n    </tr>\n    <tr>\n      <td>14800</td>\n      <td>1.952500</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>1.935700</td>\n    </tr>\n    <tr>\n      <td>15200</td>\n      <td>1.903600</td>\n    </tr>\n    <tr>\n      <td>15400</td>\n      <td>1.965000</td>\n    </tr>\n    <tr>\n      <td>15600</td>\n      <td>1.892200</td>\n    </tr>\n    <tr>\n      <td>15800</td>\n      <td>1.879600</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>2.013500</td>\n    </tr>\n    <tr>\n      <td>16200</td>\n      <td>1.923700</td>\n    </tr>\n    <tr>\n      <td>16400</td>\n      <td>1.924700</td>\n    </tr>\n    <tr>\n      <td>16600</td>\n      <td>1.904900</td>\n    </tr>\n    <tr>\n      <td>16800</td>\n      <td>1.933300</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>1.913200</td>\n    </tr>\n    <tr>\n      <td>17200</td>\n      <td>1.888100</td>\n    </tr>\n    <tr>\n      <td>17400</td>\n      <td>1.936000</td>\n    </tr>\n    <tr>\n      <td>17600</td>\n      <td>1.943700</td>\n    </tr>\n    <tr>\n      <td>17800</td>\n      <td>1.920900</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>1.914200</td>\n    </tr>\n    <tr>\n      <td>18200</td>\n      <td>1.907900</td>\n    </tr>\n    <tr>\n      <td>18400</td>\n      <td>1.968500</td>\n    </tr>\n    <tr>\n      <td>18600</td>\n      <td>1.852500</td>\n    </tr>\n    <tr>\n      <td>18800</td>\n      <td>1.935800</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>1.968500</td>\n    </tr>\n    <tr>\n      <td>19200</td>\n      <td>1.910600</td>\n    </tr>\n    <tr>\n      <td>19400</td>\n      <td>1.870700</td>\n    </tr>\n    <tr>\n      <td>19600</td>\n      <td>1.930900</td>\n    </tr>\n    <tr>\n      <td>19800</td>\n      <td>1.893000</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>1.942300</td>\n    </tr>\n    <tr>\n      <td>20200</td>\n      <td>1.948100</td>\n    </tr>\n    <tr>\n      <td>20400</td>\n      <td>1.924700</td>\n    </tr>\n    <tr>\n      <td>20600</td>\n      <td>1.937900</td>\n    </tr>\n    <tr>\n      <td>20800</td>\n      <td>1.928500</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>1.916200</td>\n    </tr>\n    <tr>\n      <td>21200</td>\n      <td>1.945200</td>\n    </tr>\n    <tr>\n      <td>21400</td>\n      <td>1.934200</td>\n    </tr>\n    <tr>\n      <td>21600</td>\n      <td>1.850000</td>\n    </tr>\n    <tr>\n      <td>21800</td>\n      <td>1.934500</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>1.908900</td>\n    </tr>\n    <tr>\n      <td>22200</td>\n      <td>1.901900</td>\n    </tr>\n    <tr>\n      <td>22400</td>\n      <td>1.917400</td>\n    </tr>\n    <tr>\n      <td>22600</td>\n      <td>1.865900</td>\n    </tr>\n    <tr>\n      <td>22800</td>\n      <td>1.892700</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>1.900600</td>\n    </tr>\n    <tr>\n      <td>23200</td>\n      <td>1.913000</td>\n    </tr>\n    <tr>\n      <td>23400</td>\n      <td>1.925100</td>\n    </tr>\n    <tr>\n      <td>23600</td>\n      <td>1.940300</td>\n    </tr>\n    <tr>\n      <td>23800</td>\n      <td>1.909900</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>1.925700</td>\n    </tr>\n    <tr>\n      <td>24200</td>\n      <td>1.898800</td>\n    </tr>\n    <tr>\n      <td>24400</td>\n      <td>1.821300</td>\n    </tr>\n    <tr>\n      <td>24600</td>\n      <td>1.836100</td>\n    </tr>\n    <tr>\n      <td>24800</td>\n      <td>1.829100</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>1.896100</td>\n    </tr>\n    <tr>\n      <td>25200</td>\n      <td>1.852500</td>\n    </tr>\n    <tr>\n      <td>25400</td>\n      <td>1.851900</td>\n    </tr>\n    <tr>\n      <td>25600</td>\n      <td>1.794600</td>\n    </tr>\n    <tr>\n      <td>25800</td>\n      <td>1.838200</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>1.835300</td>\n    </tr>\n    <tr>\n      <td>26200</td>\n      <td>1.831100</td>\n    </tr>\n    <tr>\n      <td>26400</td>\n      <td>1.756800</td>\n    </tr>\n    <tr>\n      <td>26600</td>\n      <td>1.838900</td>\n    </tr>\n    <tr>\n      <td>26800</td>\n      <td>1.867500</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>1.831500</td>\n    </tr>\n    <tr>\n      <td>27200</td>\n      <td>1.835900</td>\n    </tr>\n    <tr>\n      <td>27400</td>\n      <td>1.813500</td>\n    </tr>\n    <tr>\n      <td>27600</td>\n      <td>1.849300</td>\n    </tr>\n    <tr>\n      <td>27800</td>\n      <td>1.826500</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>1.857100</td>\n    </tr>\n    <tr>\n      <td>28200</td>\n      <td>1.836100</td>\n    </tr>\n    <tr>\n      <td>28400</td>\n      <td>1.881900</td>\n    </tr>\n    <tr>\n      <td>28600</td>\n      <td>1.805800</td>\n    </tr>\n    <tr>\n      <td>28800</td>\n      <td>1.824800</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>1.806500</td>\n    </tr>\n    <tr>\n      <td>29200</td>\n      <td>1.823100</td>\n    </tr>\n    <tr>\n      <td>29400</td>\n      <td>1.802900</td>\n    </tr>\n    <tr>\n      <td>29600</td>\n      <td>1.793700</td>\n    </tr>\n    <tr>\n      <td>29800</td>\n      <td>1.850000</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>1.820800</td>\n    </tr>\n    <tr>\n      <td>30200</td>\n      <td>1.834300</td>\n    </tr>\n    <tr>\n      <td>30400</td>\n      <td>1.815400</td>\n    </tr>\n    <tr>\n      <td>30600</td>\n      <td>1.842900</td>\n    </tr>\n    <tr>\n      <td>30800</td>\n      <td>1.850100</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>1.849400</td>\n    </tr>\n    <tr>\n      <td>31200</td>\n      <td>1.801900</td>\n    </tr>\n    <tr>\n      <td>31400</td>\n      <td>1.860400</td>\n    </tr>\n    <tr>\n      <td>31600</td>\n      <td>1.818500</td>\n    </tr>\n    <tr>\n      <td>31800</td>\n      <td>1.778500</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>1.791800</td>\n    </tr>\n    <tr>\n      <td>32200</td>\n      <td>1.849000</td>\n    </tr>\n    <tr>\n      <td>32400</td>\n      <td>1.791100</td>\n    </tr>\n    <tr>\n      <td>32600</td>\n      <td>1.784200</td>\n    </tr>\n    <tr>\n      <td>32800</td>\n      <td>1.828900</td>\n    </tr>\n    <tr>\n      <td>33000</td>\n      <td>1.763800</td>\n    </tr>\n    <tr>\n      <td>33200</td>\n      <td>1.825200</td>\n    </tr>\n    <tr>\n      <td>33400</td>\n      <td>1.855600</td>\n    </tr>\n    <tr>\n      <td>33600</td>\n      <td>1.783600</td>\n    </tr>\n    <tr>\n      <td>33800</td>\n      <td>1.827400</td>\n    </tr>\n    <tr>\n      <td>34000</td>\n      <td>1.784000</td>\n    </tr>\n    <tr>\n      <td>34200</td>\n      <td>1.819800</td>\n    </tr>\n    <tr>\n      <td>34400</td>\n      <td>1.791600</td>\n    </tr>\n    <tr>\n      <td>34600</td>\n      <td>1.854500</td>\n    </tr>\n    <tr>\n      <td>34800</td>\n      <td>1.793200</td>\n    </tr>\n    <tr>\n      <td>35000</td>\n      <td>1.842800</td>\n    </tr>\n    <tr>\n      <td>35200</td>\n      <td>1.786900</td>\n    </tr>\n    <tr>\n      <td>35400</td>\n      <td>1.840900</td>\n    </tr>\n    <tr>\n      <td>35600</td>\n      <td>1.817100</td>\n    </tr>\n    <tr>\n      <td>35800</td>\n      <td>1.831900</td>\n    </tr>\n    <tr>\n      <td>36000</td>\n      <td>1.802000</td>\n    </tr>\n    <tr>\n      <td>36200</td>\n      <td>1.830900</td>\n    </tr>\n    <tr>\n      <td>36400</td>\n      <td>1.797200</td>\n    </tr>\n    <tr>\n      <td>36600</td>\n      <td>1.720100</td>\n    </tr>\n    <tr>\n      <td>36800</td>\n      <td>1.760800</td>\n    </tr>\n    <tr>\n      <td>37000</td>\n      <td>1.803200</td>\n    </tr>\n    <tr>\n      <td>37200</td>\n      <td>1.771100</td>\n    </tr>\n    <tr>\n      <td>37400</td>\n      <td>1.686300</td>\n    </tr>\n    <tr>\n      <td>37600</td>\n      <td>1.739600</td>\n    </tr>\n    <tr>\n      <td>37800</td>\n      <td>1.705700</td>\n    </tr>\n    <tr>\n      <td>38000</td>\n      <td>1.785100</td>\n    </tr>\n    <tr>\n      <td>38200</td>\n      <td>1.727600</td>\n    </tr>\n    <tr>\n      <td>38400</td>\n      <td>1.746400</td>\n    </tr>\n    <tr>\n      <td>38600</td>\n      <td>1.741100</td>\n    </tr>\n    <tr>\n      <td>38800</td>\n      <td>1.725200</td>\n    </tr>\n    <tr>\n      <td>39000</td>\n      <td>1.734400</td>\n    </tr>\n    <tr>\n      <td>39200</td>\n      <td>1.716100</td>\n    </tr>\n    <tr>\n      <td>39400</td>\n      <td>1.694300</td>\n    </tr>\n    <tr>\n      <td>39600</td>\n      <td>1.745800</td>\n    </tr>\n    <tr>\n      <td>39800</td>\n      <td>1.705700</td>\n    </tr>\n    <tr>\n      <td>40000</td>\n      <td>1.758400</td>\n    </tr>\n    <tr>\n      <td>40200</td>\n      <td>1.822900</td>\n    </tr>\n    <tr>\n      <td>40400</td>\n      <td>1.734000</td>\n    </tr>\n    <tr>\n      <td>40600</td>\n      <td>1.747500</td>\n    </tr>\n    <tr>\n      <td>40800</td>\n      <td>1.745600</td>\n    </tr>\n    <tr>\n      <td>41000</td>\n      <td>1.771700</td>\n    </tr>\n    <tr>\n      <td>41200</td>\n      <td>1.727100</td>\n    </tr>\n    <tr>\n      <td>41400</td>\n      <td>1.842600</td>\n    </tr>\n    <tr>\n      <td>41600</td>\n      <td>1.763200</td>\n    </tr>\n    <tr>\n      <td>41800</td>\n      <td>1.758600</td>\n    </tr>\n    <tr>\n      <td>42000</td>\n      <td>1.713700</td>\n    </tr>\n    <tr>\n      <td>42200</td>\n      <td>1.724400</td>\n    </tr>\n    <tr>\n      <td>42400</td>\n      <td>1.752100</td>\n    </tr>\n    <tr>\n      <td>42600</td>\n      <td>1.686400</td>\n    </tr>\n    <tr>\n      <td>42800</td>\n      <td>1.729800</td>\n    </tr>\n    <tr>\n      <td>43000</td>\n      <td>1.711900</td>\n    </tr>\n    <tr>\n      <td>43200</td>\n      <td>1.751900</td>\n    </tr>\n    <tr>\n      <td>43400</td>\n      <td>1.744600</td>\n    </tr>\n    <tr>\n      <td>43600</td>\n      <td>1.742000</td>\n    </tr>\n    <tr>\n      <td>43800</td>\n      <td>1.707700</td>\n    </tr>\n    <tr>\n      <td>44000</td>\n      <td>1.762200</td>\n    </tr>\n    <tr>\n      <td>44200</td>\n      <td>1.794600</td>\n    </tr>\n    <tr>\n      <td>44400</td>\n      <td>1.697500</td>\n    </tr>\n    <tr>\n      <td>44600</td>\n      <td>1.697100</td>\n    </tr>\n    <tr>\n      <td>44800</td>\n      <td>1.715500</td>\n    </tr>\n    <tr>\n      <td>45000</td>\n      <td>1.742400</td>\n    </tr>\n    <tr>\n      <td>45200</td>\n      <td>1.698200</td>\n    </tr>\n    <tr>\n      <td>45400</td>\n      <td>1.709000</td>\n    </tr>\n    <tr>\n      <td>45600</td>\n      <td>1.747100</td>\n    </tr>\n    <tr>\n      <td>45800</td>\n      <td>1.754600</td>\n    </tr>\n    <tr>\n      <td>46000</td>\n      <td>1.737100</td>\n    </tr>\n    <tr>\n      <td>46200</td>\n      <td>1.732600</td>\n    </tr>\n    <tr>\n      <td>46400</td>\n      <td>1.687100</td>\n    </tr>\n    <tr>\n      <td>46600</td>\n      <td>1.736300</td>\n    </tr>\n    <tr>\n      <td>46800</td>\n      <td>1.726400</td>\n    </tr>\n    <tr>\n      <td>47000</td>\n      <td>1.716500</td>\n    </tr>\n    <tr>\n      <td>47200</td>\n      <td>1.700500</td>\n    </tr>\n    <tr>\n      <td>47400</td>\n      <td>1.704200</td>\n    </tr>\n    <tr>\n      <td>47600</td>\n      <td>1.764100</td>\n    </tr>\n    <tr>\n      <td>47800</td>\n      <td>1.711900</td>\n    </tr>\n    <tr>\n      <td>48000</td>\n      <td>1.755900</td>\n    </tr>\n    <tr>\n      <td>48200</td>\n      <td>1.769000</td>\n    </tr>\n    <tr>\n      <td>48400</td>\n      <td>1.679800</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=48472, training_loss=1.8960516457904741, metrics={'train_runtime': 4271.6558, 'train_samples_per_second': 11.347, 'train_steps_per_second': 11.347, 'total_flos': 1.3602720526467072e+16, 'train_loss': 1.8960516457904741, 'epoch': 4.0})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    #{\"role\" : \"system\", \"content\" : ''},\n",
        "    {\"role\": \"user\", \"content\": \"Hello, My name is Sahas.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Hi, Sahas. How are you?\"},\n",
        "    {\"role\": \"user\", \"content\": \"I am Great, How are you?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"I am fine.\"},\n",
        "    {\"role\": \"user\", \"content\": \"what is my nam?\"},\n",
        "]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-25T07:41:05.514621Z",
          "iopub.execute_input": "2024-03-25T07:41:05.515008Z",
          "iopub.status.idle": "2024-03-25T07:41:05.520546Z",
          "shell.execute_reply.started": "2024-03-25T07:41:05.514977Z",
          "shell.execute_reply": "2024-03-25T07:41:05.519403Z"
        },
        "trusted": true,
        "id": "QYx2gtXoe9Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "WuixQyjTe9Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt = tokenizer.apply_chat_template(messages, tokenize = False)\n",
        "#input_ids = tokenizer(prompt, return_tensors = \"pt\").input_ids\n",
        "#input_ids = tokenizer(prompt , return_tensors = \"pt\").to(\"cuda\")\n",
        "input_ids = tokenizer.apply_chat_template(messages, truncation=False, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "peft_model_result = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=15,eos_token_id = 50256))\n",
        "peft_model_text_output = tokenizer.decode(peft_model_result[0], skip_special_tokens=True)\n",
        "print(peft_model_text_output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-25T07:41:06.096760Z",
          "iopub.execute_input": "2024-03-25T07:41:06.097494Z",
          "iopub.status.idle": "2024-03-25T07:41:06.509355Z",
          "shell.execute_reply.started": "2024-03-25T07:41:06.097444Z",
          "shell.execute_reply": "2024-03-25T07:41:06.508344Z"
        },
        "trusted": true,
        "id": "Z1asUnPYe9Gd",
        "outputId": "021f3a2d-c6eb-4591-baf8-ce418237249e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "<|user|>\nHello, My name is Sahas.\n<|assistant|>\nHi, Sahas. How are you?\n<|user|>\nI am Great, How are you?\n<|assistant|>\nI am fine.\n<|user|>\nwhat is my nam?\n<|assistant|>\n My name is Wang Lin.How are you?     \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "g_Uw7jUTe9Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "iHma7Mgke9Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.apply_chat_template(messages, tokenize = False, add_generation_prompt=True)\n",
        "input_ids"
      ],
      "metadata": {
        "trusted": true,
        "id": "jcPRhnCWe9Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /kaggle/working/openai_gpt_large_model.zip /kaggle/working/openai_gpt_med_r64"
      ],
      "metadata": {
        "trusted": true,
        "id": "5LMbdaJFe9Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./openai_gpt_med_r64\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "po4og-ARe9Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T06:45:25.969083Z",
          "iopub.execute_input": "2024-03-24T06:45:25.969732Z",
          "iopub.status.idle": "2024-03-24T06:45:37.484866Z",
          "shell.execute_reply.started": "2024-03-24T06:45:25.969698Z",
          "shell.execute_reply": "2024-03-24T06:45:37.483563Z"
        },
        "trusted": true,
        "id": "dcwWtB_we9Gd",
        "outputId": "c22c9a59-cf40-49b9-c66b-f8752fc7e8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.21.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2023.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.7.22)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T06:45:37.487297Z",
          "iopub.execute_input": "2024-03-24T06:45:37.487639Z",
          "iopub.status.idle": "2024-03-24T06:45:37.515466Z",
          "shell.execute_reply.started": "2024-03-24T06:45:37.487608Z",
          "shell.execute_reply": "2024-03-24T06:45:37.514548Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "12afca231229433c9a4685338847af66"
          ]
        },
        "id": "FTie9d7je9Ge",
        "outputId": "587cd4e1-12b2-4115-cc67-e9147c832e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12afca231229433c9a4685338847af66"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(\"SSahas/openai_community_med_r32_a32_E3, loss: 1.59 \")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T06:46:13.339500Z",
          "iopub.execute_input": "2024-03-24T06:46:13.340287Z",
          "iopub.status.idle": "2024-03-24T06:46:20.114903Z",
          "shell.execute_reply.started": "2024-03-24T06:46:13.340243Z",
          "shell.execute_reply": "2024-03-24T06:46:20.113584Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "fb684fdd556c4332b2560117be0929a0",
            "a7bdad23f7254773ae3fb8e911fb4402",
            "d8686afaa5dd4516a06ab81e88f4dd7a"
          ]
        },
        "id": "0-2WFTzge9Ge",
        "outputId": "440bbb90-eb05-4e09-f535-18b2776a7a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "training_args.bin:   0%|          | 0.00/4.47k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb684fdd556c4332b2560117be0929a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7bdad23f7254773ae3fb8e911fb4402"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.safetensors:   0%|          | 0.00/12.6M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8686afaa5dd4516a06ab81e88f4dd7a"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 155,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/SSahas/openai_community_med_e3/commit/c20639554eaf2d1fa83d1bb3f961c547b6eeadb8', commit_message='SSahas/openai_community_med_r32_a32_E3, loss: 1.59 ', commit_description='', oid='c20639554eaf2d1fa83d1bb3f961c547b6eeadb8', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate rouge_score"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T15:26:28.604776Z",
          "iopub.execute_input": "2024-03-26T15:26:28.605690Z",
          "iopub.status.idle": "2024-03-26T15:26:42.695090Z",
          "shell.execute_reply.started": "2024-03-26T15:26:28.605653Z",
          "shell.execute_reply": "2024-03-26T15:26:42.693942Z"
        },
        "trusted": true,
        "id": "1GgGayI2e9Ge",
        "outputId": "ecc4f352-4e55-432b-fa9c-00a1dbdd035f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.12.2)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=8a6d11738ab83f88b93318800a75f295b3fe06f1460ea84bec048a90d412ed09\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, evaluate\nSuccessfully installed evaluate-0.4.1 rouge_score-0.1.2\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer.model_max_length"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-25T07:41:31.769356Z",
          "iopub.execute_input": "2024-03-25T07:41:31.769794Z",
          "iopub.status.idle": "2024-03-25T07:41:31.775668Z",
          "shell.execute_reply.started": "2024-03-25T07:41:31.769755Z",
          "shell.execute_reply": "2024-03-25T07:41:31.774333Z"
        },
        "trusted": true,
        "id": "z3YomcmFe9Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "rouge = evaluate.load('rouge')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T15:26:42.697476Z",
          "iopub.execute_input": "2024-03-26T15:26:42.697897Z",
          "iopub.status.idle": "2024-03-26T15:26:44.152304Z",
          "shell.execute_reply.started": "2024-03-26T15:26:42.697840Z",
          "shell.execute_reply": "2024-03-26T15:26:44.151540Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "a0185e7d1e9d489fb654b6713baa471f"
          ]
        },
        "id": "-gls1psQe9Ge",
        "outputId": "5aedf158-5167-48fe-8984-4d9c90b7427b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0185e7d1e9d489fb654b6713baa471f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(Data, tokenize, add_generation_prompt):\n",
        "  processed_data = []\n",
        "  label_data  = []\n",
        "  original_labels = []\n",
        "  for dialogs in Data:\n",
        "    flag = 0\n",
        "    wrapped_dialogues = []\n",
        "    labels = []\n",
        "    for dialog in dialogs['dialog']:\n",
        "      if flag == 0:\n",
        "        wrapped_dialog = {\"role\" : \"user\", \"content\" : dialog}\n",
        "        wrapped_dialogues.append(wrapped_dialog)\n",
        "        flag = 1\n",
        "      else:\n",
        "        wrapped_dialog = {\"role\" : \"assistant\", \"content\" : dialog}\n",
        "        wrapped_dialogues.append(wrapped_dialog)\n",
        "        flag = 0\n",
        "    if wrapped_dialogues[-1]['role'] == \"assistant\":\n",
        "      #label = [{\"role\": \"assisitant\", \"content\" : wrapped_dialogues[-1]['content']}]\n",
        "      label = str(wrapped_dialogues[-1]['content'])\n",
        "      original_labels.append(wrapped_dialogues[-1]['content'])\n",
        "      wrapped_dialogues = wrapped_dialogues[0:-1]\n",
        "\n",
        "    else:\n",
        "      #label = [{\"role\": \"assisitant\", \"content\" : wrapped_dialogues[-2]['content']}]\n",
        "      label = str(wrapped_dialogues[-2]['content'])\n",
        "      original_labels.append(wrapped_dialogues[-2]['content'])\n",
        "      wrapped_dialogues = wrapped_dialogues[0:-2]\n",
        "    #wrapped_dialogues = tokenizer.apply_chat_template(wrapped_dialogues,padding=False, truncation=False,  tokenize=tokenize, add_generation_prompt=add_generation_prompt)\n",
        "    #label = tokenizer.apply_chat_template(label,padding=False, truncation=False,  tokenize=tokenize, add_generation_prompt=False)\n",
        "    processed_data.append(wrapped_dialogues)\n",
        "    label_data.append(label)\n",
        "    output  = pd.DataFrame({\"inputs\": processed_data,\"labels\" : label_data})\n",
        "    #output = pd.DataFrame({\"inputs\" : processed_data})\n",
        "    #output  = pd.DataFrame({\"inputs\": processed_data,\"labels\" : label_data, \"ori_labels\" : original_labels})\n",
        "  return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T15:26:44.153269Z",
          "iopub.execute_input": "2024-03-26T15:26:44.153514Z",
          "iopub.status.idle": "2024-03-26T15:26:44.163006Z",
          "shell.execute_reply.started": "2024-03-26T15:26:44.153492Z",
          "shell.execute_reply": "2024-03-26T15:26:44.162084Z"
        },
        "trusted": true,
        "id": "yyS-H4D4e9Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function_1st_reply(Data, tokenize, add_generation_prompt):\n",
        "  processed_data = []\n",
        "  label_data  = []\n",
        "  original_labels = []\n",
        "  for dialogs in Data:\n",
        "    flag = 0\n",
        "    wrapped_dialogues = []\n",
        "    labels = []\n",
        "    for dialog in dialogs['dialog']:\n",
        "      if flag == 0:\n",
        "        wrapped_dialog = {\"role\" : \"user\", \"content\" : dialog}\n",
        "        wrapped_dialogues.append(wrapped_dialog)\n",
        "        flag = 1\n",
        "      else:\n",
        "        wrapped_dialog = {\"role\" : \"assistant\", \"content\" : dialog}\n",
        "        wrapped_dialogues.append(wrapped_dialog)\n",
        "        flag = 0\n",
        "\n",
        "    processed_data.append(wrapped_dialogues[0])\n",
        "    label_data.append(wrapped_dialogues[1]['content'])\n",
        "    output  = pd.DataFrame({\"inputs\": processed_data,\"labels\" : label_data})\n",
        "    #output = pd.DataFrame({\"inputs\" : processed_data})\n",
        "    #output  = pd.DataFrame({\"inputs\": processed_data,\"labels\" : label_data, \"ori_labels\" : original_labels})\n",
        "  return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T15:26:44.164794Z",
          "iopub.execute_input": "2024-03-26T15:26:44.165118Z",
          "iopub.status.idle": "2024-03-26T15:26:44.177016Z",
          "shell.execute_reply.started": "2024-03-26T15:26:44.165086Z",
          "shell.execute_reply": "2024-03-26T15:26:44.176228Z"
        },
        "trusted": true,
        "id": "-SMc4zave9Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7sk0u0_Ze9Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = preprocess_function(dataset['test'], tokenize=False, add_generation_prompt=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T15:26:46.366691Z",
          "iopub.execute_input": "2024-03-26T15:26:46.367531Z",
          "iopub.status.idle": "2024-03-26T15:26:46.757067Z",
          "shell.execute_reply.started": "2024-03-26T15:26:46.367497Z",
          "shell.execute_reply": "2024-03-26T15:26:46.756072Z"
        },
        "trusted": true,
        "id": "N0nKVHFQe9Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T15:26:46.758600Z",
          "iopub.execute_input": "2024-03-26T15:26:46.758919Z",
          "iopub.status.idle": "2024-03-26T15:26:46.795947Z",
          "shell.execute_reply.started": "2024-03-26T15:26:46.758893Z",
          "shell.execute_reply": "2024-03-26T15:26:46.795037Z"
        },
        "trusted": true,
        "id": "cwk4w9ONe9Gf",
        "outputId": "1e3ffc50-2e25-4947-94a4-6d3bdcfa367d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 39,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                inputs  \\\n0    [{'role': 'user', 'content': 'Hey man , you wa...   \n1    [{'role': 'user', 'content': 'The taxi drivers...   \n2    [{'role': 'user', 'content': 'We've managed to...   \n3    [{'role': 'user', 'content': 'Believe it or no...   \n4    [{'role': 'user', 'content': 'What are your pe...   \n..                                                 ...   \n995  [{'role': 'user', 'content': 'Frank ’ s gettin...   \n996  [{'role': 'user', 'content': 'OK . Come back i...   \n997  [{'role': 'user', 'content': 'Do you have any ...   \n998  [{'role': 'user', 'content': 'Jenny , what's w...   \n999  [{'role': 'user', 'content': 'What a nice day ...   \n\n                                                labels  \n0     I want you to put your hands behind your head...  \n1                         It is really a hot potato .   \n2           What other sources of energy do you use ?   \n3                                          Let's go !   \n4     Yes , I like travelling . I am young , and un...  \n..                                                 ...  \n995            Have they set a date for the wedding ?   \n996                  Mam , another minute , could I ?   \n997                                    Yes , stones .   \n998   Mary told me that she had seen you with John ...  \n999    wonderful ! I'll start packing our suitcases .   \n\n[1000 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inputs</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[{'role': 'user', 'content': 'Hey man , you wa...</td>\n      <td>I want you to put your hands behind your head...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[{'role': 'user', 'content': 'The taxi drivers...</td>\n      <td>It is really a hot potato .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[{'role': 'user', 'content': 'We've managed to...</td>\n      <td>What other sources of energy do you use ?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[{'role': 'user', 'content': 'Believe it or no...</td>\n      <td>Let's go !</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[{'role': 'user', 'content': 'What are your pe...</td>\n      <td>Yes , I like travelling . I am young , and un...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>[{'role': 'user', 'content': 'Frank ’ s gettin...</td>\n      <td>Have they set a date for the wedding ?</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>[{'role': 'user', 'content': 'OK . Come back i...</td>\n      <td>Mam , another minute , could I ?</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>[{'role': 'user', 'content': 'Do you have any ...</td>\n      <td>Yes , stones .</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>[{'role': 'user', 'content': 'Jenny , what's w...</td>\n      <td>Mary told me that she had seen you with John ...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>[{'role': 'user', 'content': 'What a nice day ...</td>\n      <td>wonderful ! I'll start packing our suitcases .</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for i, x in test_ds.iterrows():\n",
        "  #print(x['inputs'])\n",
        "  input_ids = tokenizer.apply_chat_template(x['inputs'], truncation=False, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "  peft_model_result = model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=20, eos_token_id = 50256))\n",
        "\n",
        "  sliced_peft_model_text_output = tokenizer.decode(peft_model_result[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
        "  #index = sliced_peft_model_text_output.find(\"\\nuser\")\n",
        "\n",
        "  predictions.append(sliced_peft_model_text_output)\n",
        "\n",
        "\n",
        "  if len(predictions) == 50:\n",
        "    break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-26T15:26:49.143816Z",
          "iopub.execute_input": "2024-03-26T15:26:49.144493Z",
          "iopub.status.idle": "2024-03-26T15:27:05.967896Z",
          "shell.execute_reply.started": "2024-03-26T15:26:49.144465Z",
          "shell.execute_reply": "2024-03-26T15:27:05.967065Z"
        },
        "trusted": true,
        "id": "LnMUAAK_e9Gf",
        "outputId": "7469f7be-8d5a-4e52-ed1f-77f445f75d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zr2vKZJ7e9Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B1-1PALEe9Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_model_results_last = rouge.compute(\n",
        "    predictions=predictions,\n",
        "    references=test_ds['labels'][0:len(predictions)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "original_model_results_last"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-25T07:42:40.221952Z",
          "iopub.execute_input": "2024-03-25T07:42:40.222869Z",
          "iopub.status.idle": "2024-03-25T07:42:40.495468Z",
          "shell.execute_reply.started": "2024-03-25T07:42:40.222835Z",
          "shell.execute_reply": "2024-03-25T07:42:40.494522Z"
        },
        "trusted": true,
        "id": "WTk6UaZ9e9Gg",
        "outputId": "5c1a2249-31be-4b19-f5bc-bb1334e856ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 55,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'rouge1': 0.21255654577214209,\n 'rouge2': 0.09827546432062562,\n 'rougeL': 0.20128463669249905,\n 'rougeLsum': 0.20111380883718843}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eWKpXlfNe9Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NbdWHUCMe9Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WhbjfLqde9Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wSliR1S_e9Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9eKWhmpLe9Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "8OZrmnnAe9Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tkt0xhmme9Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "go0BFI5me9Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame({\"inputs\": predictions,\"labels\" : test_ds['labels'][0:len(predictions)]})\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-22T05:29:01.028648Z",
          "iopub.execute_input": "2024-03-22T05:29:01.029621Z",
          "iopub.status.idle": "2024-03-22T05:29:01.051706Z",
          "shell.execute_reply.started": "2024-03-22T05:29:01.029573Z",
          "shell.execute_reply": "2024-03-22T05:29:01.050797Z"
        },
        "trusted": true,
        "id": "mrJsd2JOe9Gi",
        "outputId": "7a9d9a0c-bf8b-416f-bba0-0fb528ea851b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 32,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                            inputs  \\\n0            I got some weed, some hash, some acid   \n1                      I think they are right.  \\n   \n2                 That sounds like a good idea. \\n   \n3                               OK.  \\nuser\\n I'll   \n4                 Yes, I ’ m available for travel.   \n5          I think we will be able to get there in   \n6                            No, I'm sorry. \\nuser   \n7                            Thank you.   \\nuser\\n   \n8                       You're welcome. \\nuser\\n I   \n9                          I think I'd be fine. \\n   \n10                                 OK.    \\nuser\\n   \n11                          I'll be there.  \\nuser   \n12                             I'm sorry too.   \\n   \n13                              I see.  \\nuser\\n I   \n14                             It's $ 50 a day.      \n15             That's right. Thank you very much.    \n16                         That's right.  \\nuser\\n   \n17                           Thank you.   \\nuser\\n   \n18                 You're welcome. \\nuser\\n Thanks   \n19           I am afraid I can't use the bathroom.   \n20                     I'll write you a ticket.      \n21                            Sure.  \\nuser\\n I'll   \n22   My father is a businessman and my mother is a   \n23       I think I'll try to eat some chicken next   \n24                       OK. \\nuser\\n Here you are   \n25                         Thank you. \\nuser\\n I �   \n26                   I think I ’ m going to have a   \n27                           OK.  \\nuser\\n Here is   \n28                 I'm sorry. I'll just have to go   \n29         I have a good writing ability, but I am   \n30                   I'd like to be called John.     \n31                   I'm not tired, but I'm tired.   \n32             I'll be able to help you tomorrow.    \n33   I learned to use the fax machine and the dupl   \n34                          I will. I will. \\nuser   \n35                        You're right. \\nuser\\n I   \n36                       I ’ m afraid we ’ ll have   \n37                         Yes, here you are.   \\n   \n38                I ’ ll tell you what I think you   \n39           I hope you will be able to come back.   \n\n                                               labels  \n0    I want you to put your hands behind your head...  \n1                        It is really a hot potato .   \n2          What other sources of energy do you use ?   \n3                                         Let's go !   \n4    Yes , I like travelling . I am young , and un...  \n5    we can ’ t . if we went that fast , we would ...  \n6                You can take it in a couple weeks .   \n7                              Thank you very much .   \n8          But you must cook that dinner next time .   \n9    I can't really deal with any distractions rig...  \n10   Well , now I want to change the date from 24t...  \n11   Oh , I just remembered I've got a report to w...  \n12             I'll call the lost and found office .   \n13                          Can you hold it for me ?   \n14                             It's free of charge .   \n15   Thank you so much , Mr . Sandals . We look fo...  \n16         I'll just go and check it for you , sir .   \n17             That's very kind of you . Thank you .   \n18    These roses should make your wife very happy .   \n19   Yes , but 4 of them are broken . Can you send...  \n20               Here you go . Don't do that again .   \n21                                            Sure .   \n22   There are three in my family , my parents and...  \n23       I know it does , and that's because it is .   \n24            Thanks . How much would that come to ?   \n25              Thank you very much . See you then .   \n26                            Good . Anything else ?   \n27                             Thank you very much .   \n28                    what would you do without me ?   \n29   Of course . I've loved writing since I was a ...  \n30                         My name is Ron Kollwitz .   \n31   Yes , it was quite a long flight . I'm glad t...  \n32           Why don't you ask Bill if he can help ?   \n33   Above all , I have learned that what is good ...  \n34   I just don't know how to bring it up . Well ,...  \n35                       That was very lazy of you .   \n36                That sounds absolutely fantastic .   \n37   Here you go . By the way , is it possible to ...  \n38                      Can I have my $ 200 please ?   \n39   Fine . Well , thanks for calling and letting ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inputs</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I got some weed, some hash, some acid</td>\n      <td>I want you to put your hands behind your head...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I think they are right.  \\n</td>\n      <td>It is really a hot potato .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>That sounds like a good idea. \\n</td>\n      <td>What other sources of energy do you use ?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OK.  \\nuser\\n I'll</td>\n      <td>Let's go !</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Yes, I ’ m available for travel.</td>\n      <td>Yes , I like travelling . I am young , and un...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>I think we will be able to get there in</td>\n      <td>we can ’ t . if we went that fast , we would ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>No, I'm sorry. \\nuser</td>\n      <td>You can take it in a couple weeks .</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Thank you.   \\nuser\\n</td>\n      <td>Thank you very much .</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>You're welcome. \\nuser\\n I</td>\n      <td>But you must cook that dinner next time .</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>I think I'd be fine. \\n</td>\n      <td>I can't really deal with any distractions rig...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>OK.    \\nuser\\n</td>\n      <td>Well , now I want to change the date from 24t...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>I'll be there.  \\nuser</td>\n      <td>Oh , I just remembered I've got a report to w...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>I'm sorry too.   \\n</td>\n      <td>I'll call the lost and found office .</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>I see.  \\nuser\\n I</td>\n      <td>Can you hold it for me ?</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>It's $ 50 a day.</td>\n      <td>It's free of charge .</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>That's right. Thank you very much.</td>\n      <td>Thank you so much , Mr . Sandals . We look fo...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>That's right.  \\nuser\\n</td>\n      <td>I'll just go and check it for you , sir .</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Thank you.   \\nuser\\n</td>\n      <td>That's very kind of you . Thank you .</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>You're welcome. \\nuser\\n Thanks</td>\n      <td>These roses should make your wife very happy .</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>I am afraid I can't use the bathroom.</td>\n      <td>Yes , but 4 of them are broken . Can you send...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>I'll write you a ticket.</td>\n      <td>Here you go . Don't do that again .</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Sure.  \\nuser\\n I'll</td>\n      <td>Sure .</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>My father is a businessman and my mother is a</td>\n      <td>There are three in my family , my parents and...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>I think I'll try to eat some chicken next</td>\n      <td>I know it does , and that's because it is .</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>OK. \\nuser\\n Here you are</td>\n      <td>Thanks . How much would that come to ?</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Thank you. \\nuser\\n I �</td>\n      <td>Thank you very much . See you then .</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>I think I ’ m going to have a</td>\n      <td>Good . Anything else ?</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>OK.  \\nuser\\n Here is</td>\n      <td>Thank you very much .</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>I'm sorry. I'll just have to go</td>\n      <td>what would you do without me ?</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>I have a good writing ability, but I am</td>\n      <td>Of course . I've loved writing since I was a ...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>I'd like to be called John.</td>\n      <td>My name is Ron Kollwitz .</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>I'm not tired, but I'm tired.</td>\n      <td>Yes , it was quite a long flight . I'm glad t...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>I'll be able to help you tomorrow.</td>\n      <td>Why don't you ask Bill if he can help ?</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>I learned to use the fax machine and the dupl</td>\n      <td>Above all , I have learned that what is good ...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>I will. I will. \\nuser</td>\n      <td>I just don't know how to bring it up . Well ,...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>You're right. \\nuser\\n I</td>\n      <td>That was very lazy of you .</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>I ’ m afraid we ’ ll have</td>\n      <td>That sounds absolutely fantastic .</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Yes, here you are.   \\n</td>\n      <td>Here you go . By the way , is it possible to ...</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>I ’ ll tell you what I think you</td>\n      <td>Can I have my $ 200 please ?</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>I hope you will be able to come back.</td>\n      <td>Fine . Well , thanks for calling and letting ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UHACeA41GU3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kfpZS6HEGU0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SGfBkH5vGUx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9iKqHdaEGUuZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}